# SafeSpell with Ollama Integration

SafeSpell is an application that helps detect potentially abusive, manipulative, or gaslighting language in text. This version uses Ollama for AI-powered explanations.

## Prerequisites

1. Python 3.8 or higher
2. Node.js and npm (for the frontend)
3. Ollama installed and running on your system

## Setup Instructions

### 1. Install Ollama

If you haven't already installed Ollama, follow the instructions at [Ollama's official website](https://ollama.ai/).

### 2. Pull the required model

```bash
ollama pull llama3.2
```

### 3. Backend Setup

```bash
# Navigate to the backend directory
cd backend

# Create a virtual environment
python -m venv venv

# Activate the virtual environment
# On Windows
.\venv\Scripts\activate
# On macOS/Linux
source venv/bin/activate

# Install dependencies
pip install -r requirements.txt

# Create .env file from example
cp .env.example.ollama .env

# Start the backend server
python -m app.main
```

### 4. Frontend Setup

```bash
# Navigate to the frontend directory
cd frontend

# Install dependencies
npm install

# Start the frontend development server
npm start
```

## Usage

Once both the backend and frontend servers are running:

1. Open your browser and navigate to `http://localhost:3000`
2. Enter text in the input field
3. Click "Analyze" to check for potentially harmful language
4. View the results with AI-powered explanations from Ollama

## Configuration

You can modify the following settings in the `.env` file:

- `OLLAMA_BASE_URL`: URL where Ollama is running (default: http://localhost:11434)
- `MODEL_NAME`: The Ollama model to use (default: llama3.2)
- `API_HOST`: Host for the backend server
- `API_PORT`: Port for the backend server
- `API_CORS_ORIGINS`: Allowed origins for CORS

## Troubleshooting

- Make sure Ollama is running before starting the backend server
- Check that the model specified in `.env` is available in your Ollama installation
- If you encounter issues with the API, check the backend logs for error messages