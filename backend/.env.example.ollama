# Ollama API Configuration
OLLAMA_BASE_URL=http://localhost:11434

# API Configuration
API_HOST=0.0.0.0
API_PORT=8000
API_CORS_ORIGINS=["http://localhost:3000"]

# Model Configuration
MODEL_NAME=llama3.2
# Other model options: mistral, llama2, codellama, etc.